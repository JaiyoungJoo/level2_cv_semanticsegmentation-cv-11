{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaboern as sns\n",
    "import os\n",
    "import json\n",
    "from dataset import XRayDataset, XRayDataset_path, XRayDataset_gray\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "import albumentations as A\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_ROOT = \"/opt/ml/input/data/train/DCM/\"\n",
    "LABEL_ROOT = \"/opt/ml/input/data/train/outputs_json/\"\n",
    "\n",
    "CLASSES = [\n",
    "    'finger-1', 'finger-2', 'finger-3', 'finger-4', 'finger-5',\n",
    "    'finger-6', 'finger-7', 'finger-8', 'finger-9', 'finger-10',\n",
    "    'finger-11', 'finger-12', 'finger-13', 'finger-14', 'finger-15',\n",
    "    'finger-16', 'finger-17', 'finger-18', 'finger-19', 'Trapezium',\n",
    "    'Trapezoid', 'Capitate', 'Hamate', 'Scaphoid', 'Lunate',\n",
    "    'Triquetrum', 'Pisiform', 'Radius', 'Ulna',\n",
    "]\n",
    "\n",
    "BATCH_SIZE=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define colors\n",
    "PALETTE = [\n",
    "    (220, 20, 60), (119, 11, 32), (0, 0, 142), (0, 0, 230), (106, 0, 228),\n",
    "    (0, 60, 100), (0, 80, 100), (0, 0, 70), (0, 0, 192), (250, 170, 30),\n",
    "    (100, 170, 30), (220, 220, 0), (175, 116, 175), (250, 0, 30), (165, 42, 42),\n",
    "    (255, 77, 255), (0, 226, 252), (182, 182, 255), (0, 82, 0), (120, 166, 157),\n",
    "    (110, 76, 0), (174, 57, 255), (199, 100, 0), (72, 0, 118), (255, 179, 240),\n",
    "    (0, 125, 92), (209, 0, 151), (188, 208, 182), (0, 220, 176),\n",
    "]\n",
    "\n",
    "# utility function\n",
    "# this does not care overlap\n",
    "def label2rgb(label):\n",
    "    image_size = label.shape[1:] + (3, )\n",
    "    image = np.zeros(image_size, dtype=np.uint8)\n",
    "    \n",
    "    for i, class_label in enumerate(label):\n",
    "        image[class_label == 1] = PALETTE[i]\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pngs = {\n",
    "    os.path.relpath(os.path.join(root, fname), start=IMAGE_ROOT)\n",
    "    for root, _dirs, files in os.walk(IMAGE_ROOT)\n",
    "    for fname in files\n",
    "    if os.path.splitext(fname)[1].lower() == \".png\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = y_true.flatten(2)\n",
    "    y_pred_f = y_pred.flatten(2)\n",
    "    intersection = torch.sum(y_true_f * y_pred_f, -1)\n",
    "    \n",
    "    eps = 0.0001\n",
    "    return (2. * intersection + eps) / (torch.sum(y_true_f, -1) + torch.sum(y_pred_f, -1) + eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(debug=\"False\"):\n",
    "    # dataset load\n",
    "    tf = A.Resize(1024,1024)\n",
    "    train_dataset = XRayDataset(is_train=True, transforms=tf)\n",
    "    valid_dataset = XRayDataset(is_train=False, transforms=tf)\n",
    "    original_dataset = XRayDataset_path(is_train=False)\n",
    "    if debug==\"True\":\n",
    "        train_subset_size = int(len(train_dataset) * 0.1)\n",
    "\n",
    "        # Create a random train subset of the original dataset\n",
    "        train_subset_indices = range(len(train_dataset))[:train_subset_size]\n",
    "        train_dataset = Subset(train_dataset, train_subset_indices)\n",
    "\n",
    "        # Calculate the number of samples for the valid subset\n",
    "        valid_subset_size = int(len(valid_dataset) * 0.1)\n",
    "        # Create a random valid subset of the original dataset\n",
    "        valid_subset_indices = range(len(valid_dataset))[:valid_subset_size]\n",
    "        print(valid_subset_indices)\n",
    "\n",
    "        valid_dataset = Subset(valid_dataset, valid_subset_indices)\n",
    "\n",
    "        original_dataset = Subset(original_dataset, valid_subset_indices)\n",
    "        \n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset, \n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        dataset=valid_dataset, \n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    original_loader = DataLoader(\n",
    "        dataset=original_dataset, \n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    return [train_loader, valid_loader, original_loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graydataset(debug=\"False\"):\n",
    "    # dataset load\n",
    "    # tf = A.Resize(512, 512)\n",
    "    tf = None\n",
    "    train_dataset = XRayDataset_gray(is_train=True, transforms=tf)\n",
    "    valid_dataset = XRayDataset_gray(is_train=False, transforms=tf)\n",
    "    original_dataset = XRayDataset_path(is_train=False)\n",
    "    if debug==\"True\":\n",
    "        train_subset_size = int(len(train_dataset) * 0.1)\n",
    "\n",
    "        # Create a random train subset of the original dataset\n",
    "        train_subset_indices = range(len(train_dataset))[:train_subset_size]\n",
    "        train_dataset = Subset(train_dataset, train_subset_indices)\n",
    "\n",
    "        # Calculate the number of samples for the valid subset\n",
    "        valid_subset_size = int(len(valid_dataset) * 0.1)\n",
    "\n",
    "        # Create a random valid subset of the original dataset\n",
    "        valid_subset_indices = range(len(valid_dataset))[:valid_subset_size]\n",
    "        print(valid_subset_indices)\n",
    "        valid_dataset = Subset(valid_dataset, valid_subset_indices)\n",
    "        original_dataset = Subset(original_dataset, valid_subset_indices)\n",
    "        \n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset, \n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        dataset=valid_dataset, \n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    original_loader = DataLoader(\n",
    "        dataset=original_dataset, \n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    return [train_loader, valid_loader, original_loader]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch, model, gray_model, data_loader, gray_loader, thr=0.5):\n",
    "    print(f'Start validation #{epoch:2d}')\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    gray_model = gray_model.cuda()\n",
    "    gray_model.eval()\n",
    "\n",
    "    dices = []\n",
    "    filtered_dices = []\n",
    "    all_dices = []\n",
    "    all_masks = []\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "    \n",
    "        for step, ((images, masks), (gray_images, gray_names)) in tqdm(enumerate(zip(data_loader, gray_loader)), total=len(data_loader)):\n",
    "            images, masks = images.cuda(), masks.cuda()         \n",
    "            outputs = model(images)\n",
    "\n",
    "            gray_images = gray_images.cuda()\n",
    "            gray_outputs = gray_model(gray_images)\n",
    "            \n",
    "            output_h, output_w = outputs.size(-2), outputs.size(-1)\n",
    "            mask_h, mask_w = masks.size(-2), masks.size(-1)\n",
    "            # restore original size\n",
    "            if output_h != mask_h or output_w != mask_w:\n",
    "                outputs = F.interpolate(outputs, size=(mask_h, mask_w), mode=\"bilinear\")\n",
    "            \n",
    "            gray_outputs = torch.sigmoid(gray_outputs)\n",
    "            gray_outputs = (gray_outputs > thr)\n",
    "            \n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            outputs = (outputs > thr)#.detach().cpu()\n",
    "            filtered_outputs = torch.logical_and(outputs, gray_outputs).detach().cpu()\n",
    "            masks = masks.detach().cpu()\n",
    "            # all_masks.append(np.array(outputs))\n",
    "            dice = dice_coef(outputs.detach().cpu(), masks)\n",
    "            filtered_dice = dice_coef(filtered_outputs, masks)\n",
    "            # all_dices.append(dice.mean(axis=1))\n",
    "            dices.append(dice)\n",
    "            filtered_dices.append(filtered_dice)\n",
    "    dices = torch.cat(dices, 0)\n",
    "    filtered_dices = torch.cat(filtered_dices, 0)\n",
    "\n",
    "    return [dices, filtered_dices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gray = torch.load(\"/opt/ml/input/weights/gray_FPN_gray_resnet101_True_comb_loss_100/Final_oneclass.pt\")\n",
    "model = torch.load(\"/opt/ml/input/weights/temp/Pretrained_smp_resnet101_comb_loss_tf=True_cln=True_e=100_sd=up.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 16)\n",
      "range(0, 16)\n"
     ]
    }
   ],
   "source": [
    "set_seed(21)\n",
    "train_loader, valid_loader, original_loader = make_dataset(debug=\"True\")\n",
    "train_loader_gray, valid_loader_gray, original_loader_gray = make_graydataset(debug=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validation # 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c573a981b4d45219e69e790188a5968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dices, filtered_dices = validation(1, model, model_gray, valid_loader, valid_loader_gray)    #메모리 이슈로 이미지 절반(40)만 추출합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dices = dices.mean(axis=0)\n",
    "filtered_dices = filtered_dices.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finger-1, 0.9713789224624634, 0.9739236831665039, filtered is big\n",
      "finger-2, 0.9838693737983704, 0.9859314560890198, filtered is big\n",
      "finger-3, 0.9880481958389282, 0.9891602993011475, filtered is big\n",
      "finger-4, 0.9741648435592651, 0.9777947664260864, filtered is big\n",
      "finger-5, 0.9740586876869202, 0.9769718647003174, filtered is big\n",
      "finger-6, 0.9849164485931396, 0.9866048097610474, filtered is big\n",
      "finger-7, 0.9827626943588257, 0.9841089248657227, filtered is big\n",
      "finger-8, 0.9767773151397705, 0.9790391325950623, filtered is big\n",
      "finger-9, 0.9747393131256104, 0.9768016338348389, filtered is big\n",
      "finger-10, 0.9866336584091187, 0.9879833459854126, filtered is big\n",
      "finger-11, 0.9775463342666626, 0.9793636798858643, filtered is big\n",
      "finger-12, 0.9765084385871887, 0.9782482385635376, filtered is big\n",
      "finger-13, 0.9775259494781494, 0.9790356159210205, filtered is big\n",
      "finger-14, 0.9837022423744202, 0.9858810901641846, filtered is big\n",
      "finger-15, 0.9805372953414917, 0.9821506142616272, filtered is big\n",
      "finger-16, 0.9674264192581177, 0.9704568386077881, filtered is big\n",
      "finger-17, 0.9688420295715332, 0.9720098972320557, filtered is big\n",
      "finger-18, 0.9829951524734497, 0.9848445653915405, filtered is big\n",
      "finger-19, 0.9844897985458374, 0.9856326580047607, filtered is big\n",
      "Trapezium, 0.9657067060470581, 0.9664016366004944, filtered is big\n",
      "Trapezoid, 0.950778067111969, 0.9512513875961304, filtered is big\n",
      "Capitate, 0.9753773212432861, 0.9752336740493774, dice is big\n",
      "Hamate, 0.9667220115661621, 0.9673194885253906, filtered is big\n",
      "Scaphoid, 0.9801763296127319, 0.9804292917251587, filtered is big\n",
      "Lunate, 0.9692261219024658, 0.9688877463340759, dice is big\n",
      "Triquetrum, 0.9641999006271362, 0.9645435810089111, filtered is big\n",
      "Pisiform, 0.9369850158691406, 0.9374334812164307, filtered is big\n",
      "Radius, 0.9905813932418823, 0.9919105768203735, filtered is big\n",
      "Ulna, 0.9885088205337524, 0.9899904727935791, filtered is big\n"
     ]
    }
   ],
   "source": [
    "for dice, filtered_dice in zip([dices], [filtered_dices]):\n",
    "    for i in range(len(dice)):\n",
    "        print(f\"{CLASSES[i]}, {dice[i]}, {filtered_dice[i]}\", end=\", \")\n",
    "        if dice[i] > filtered_dice[i]:\n",
    "            print(\"dice is big\")\n",
    "        else:\n",
    "            print(\"filtered is big\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
